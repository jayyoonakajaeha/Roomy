import os
import numpy as np
import json
import base64
import asyncio
from typing import List, Dict, Optional
from PIL import Image
from io import BytesIO
from fastapi import UploadFile
import google.generativeai as genai
from sentence_transformers import SentenceTransformer, util
from .models import RepairAnalysisResult, DuplicateReportInfo, RepairResponse

# ==========================================
# ğŸ”§ Configuration & Mock DB
# ==========================================

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY") # Must be set in .env
genai.configure(api_key=GOOGLE_API_KEY)

# Mock Database for Reports
REPAIR_REPORTS = [] 
NEXT_REPORT_ID = 1

# Lazy Load Models
_clip_model = None

def get_clip_model():
    global _clip_model
    if _clip_model is None:
        print("Loading CLIP Model...")
        _clip_model = SentenceTransformer('sentence-transformers/clip-ViT-B-32')
        print("CLIP Model Loaded.")
    return _clip_model

# ==========================================
# ğŸ§  AI Analysis (Gemini)
# ==========================================

async def analyze_image_with_gemini(image_bytes: bytes) -> RepairAnalysisResult:
    """
    Gemini 3 Flash to analyze image.
    Enforces Korean output and strict JSON structure.
    """
    model = genai.GenerativeModel(
        model_name="gemini-3-flash-preview",
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RepairAnalysisResult
        }
    )
    
    pil_img = Image.open(BytesIO(image_bytes))
    
    prompt = """
    ë‹¹ì‹ ì€ ì‹œì„¤ ê´€ë¦¬ ë° ì•ˆì „ ì ê²€ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. 
    ì œê³µëœ ì‚¬ì§„ì„ ë¶„ì„í•˜ì—¬ ì‹œì„¤ë¬¼ì˜ ê³ ì¥ ìƒíƒœë¥¼ ì§„ë‹¨í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
    
    **ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.**

    **ìš°ì„ ìˆœìœ„ íŒë‹¨ ê¸°ì¤€ (Priority Logic)**:
    1. **CRITICAL (ê¸´ê¸‰, ì ìˆ˜ 9-10)**: 
       - ê±°ì£¼ìì˜ ê±´ê°•/ì•ˆì „ ìœ„í˜‘ (ì˜ˆ: í•˜ìˆ˜/ë³€ê¸° ì—­ë¥˜, ê°€ìŠ¤ ëˆ„ì¶œ, ì „ì„  ë…¸ì¶œ, í˜„ê´€ë¬¸/ë³´ì•ˆì¥ì¹˜ íŒŒì†).
       - ì£¼ê±° ë¶ˆê°€ëŠ¥ ìƒíƒœ (ë‹¨ì „, ë‹¨ìˆ˜).
    2. **HIGH (ë†’ìŒ, ì ìˆ˜ 7-8)**: 
       - í•„ìˆ˜ ìƒí™œ ê¸°ëŠ¥ ë§ˆë¹„ (ì˜ˆ: ë‚œë°©/ì—ì–´ì»¨ ê³ ì¥, ëƒ‰ì¥ê³  ê³ ì¥, ì‹±í¬ëŒ€ ëˆ„ìˆ˜).
    3. **MEDIUM (ì¤‘ê°„, ì ìˆ˜ 4-6)**: 
       - ê¸°ëŠ¥ìƒ ë¶ˆí¸í•˜ë‚˜ ìƒí™œ ê°€ëŠ¥ (ì˜ˆ: ë°©ë¬¸ íŒŒì†, ì‹íƒ ì˜ì íŒŒì†, ì „ë“± 1ê°œ ë‚˜ê°).
    4. **LOW (ë‚®ìŒ, ì ìˆ˜ 1-3)**: 
       - ë¯¸ê´€ìƒ ë¬¸ì œ (ì˜ˆ: ë²½ì§€ ì°¢ì–´ì§, ìŠ¤í¬ë˜ì¹˜).

    **ë¶„ì„ í•­ëª©**:
    - item: êµ¬ì²´ì ì¸ ë¬¼ê±´ ëª…ì¹­ (í•œêµ­ì–´).
    - issue: ë¬¸ì œ í˜„ìƒ (í•œêµ­ì–´).
    - severity: CRITICAL, HIGH, MEDIUM, LOW ì¤‘ íƒ1.
    - priority_score: 1~10 ì‚¬ì´ ì •ìˆ˜.
    - reasoning: ì™œ ì´ ì‹¬ê°ë„ì¸ì§€ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª… (í•œêµ­ì–´).
    - description: ìƒí™© ìš”ì•½ (í•œêµ­ì–´).
    """
    
    try:
        response = model.generate_content([prompt, pil_img])
    except Exception as e:
        print(f"Gemini API Error: {e}")
        return RepairAnalysisResult(
            item="unknown", issue="unknown", 
            severity="MEDIUM", priority_score=5, reasoning=f"API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}", 
            description="AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )
    
    try:
        data = json.loads(response.text)
        return RepairAnalysisResult(**data)
    except Exception as e:
        print(f"Gemini JSON Parse Error: {e}, Raw: {response.text}")
        return RepairAnalysisResult(
            item="unknown", issue="unknown", 
            severity="MEDIUM", priority_score=5, reasoning="ë¶„ì„ ì‹¤íŒ¨", 
            description="ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        )

# ==========================================
# ğŸ” Duplicate Detection (CLIP)
# ==========================================

async def check_duplicates(query_emb, existing_report_ids: List[int], floor: str, room_number: Optional[str] = None) -> List[DuplicateReportInfo]:
    """
    ë°±ì—”ë“œì—ì„œ ìœ„ì¹˜ í•„í„°ë§í•œ ê¸°ì¡´ ê²Œì‹œë¬¼ ID ëª©ë¡ì— ëŒ€í•´
    CLIP ë²¡í„° ìœ ì‚¬ë„ ë¹„êµí•˜ì—¬ ì¤‘ë³µ ì—¬ë¶€ íŒë‹¨.
    """
    duplicates = []
    
    for report in REPAIR_REPORTS:
        if report['id'] not in existing_report_ids:
            continue
            
        if report.get('embedding') is not None:
            sim = util.pytorch_cos_sim(query_emb, report['embedding'])[0][0].item()
            
            # Threshold: 0.80 (80% ì´ìƒ ìœ ì‚¬ = ì¤‘ë³µ ì˜ì‹¬)
            if sim >= 0.80:
                loc_str = f"{report['floor']}ì¸µ"
                if report.get('room_number'):
                    loc_str += f" {report['room_number']}í˜¸"
                else:
                    loc_str += " (ê³µìš©)"
                    
                duplicates.append(DuplicateReportInfo(
                    reportId=report['id'],
                    similarity=round(sim, 2),
                    description=report['description'],
                    location=loc_str
                ))
    
    duplicates.sort(key=lambda x: x.similarity, reverse=True)
    return duplicates

async def save_report(analysis: RepairAnalysisResult, query_emb, floor: str, room_number: Optional[str] = None):
    """
    In-memory save for future duplicate checks. 
    """
    global NEXT_REPORT_ID
    
    REPAIR_REPORTS.append({
        "id": NEXT_REPORT_ID,
        "floor": floor,
        "room_number": room_number,
        "description": analysis.description,
        "embedding": query_emb
    })
    NEXT_REPORT_ID += 1

# ==========================================
# ğŸš€ Main Logic
# ==========================================

from .models import RepairRequest

async def process_repair_request(req: RepairRequest) -> RepairResponse:
    # 1. Read Image from Path
    try:
        with open(req.imagePath, "rb") as f:
            content = f.read()
    except Exception as e:
        raise ValueError(f"Image not found at {req.imagePath}")

    # 2. Calculate CLIP Embedding (ì‹ ê·œ ì´ë¯¸ì§€ ë²¡í„° ê³„ì‚°)
    pil_img = Image.open(BytesIO(content))
    clip_model = get_clip_model()
    query_emb = clip_model.encode(pil_img, convert_to_numpy=True)
    
    # 3. Analyze (Gemini) - ë³‘ë ¬ ì²˜ë¦¬
    analysis_task = analyze_image_with_gemini(content)
    
    # 4. Check Duplicates (ë°±ì—”ë“œê°€ í•„í„°ë§í•œ ID ëª©ë¡ê³¼ ë¹„êµ)
    duplicates_task = check_duplicates(
        query_emb, 
        req.existingReportIds,
        req.floor, 
        req.room_number
    )
    
    analysis, duplicates = await asyncio.gather(analysis_task, duplicates_task)
    
    # 5. Save current report
    await save_report(analysis, query_emb, req.floor, req.room_number)
    
    return RepairResponse(
        analysis=analysis,
        duplicates=duplicates,
        is_new=(len(duplicates) == 0)
    )
