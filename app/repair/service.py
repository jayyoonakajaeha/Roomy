import os
import numpy as np
import json
import base64
import asyncio
from typing import List, Dict, Optional
from PIL import Image
from io import BytesIO
from fastapi import UploadFile
import google.generativeai as genai
from sentence_transformers import SentenceTransformer, util
from .models import RepairAnalysisResult, DuplicateReportInfo, RepairResponse

# ==========================================
# ðŸ”§ Configuration & Mock DB
# ==========================================

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY") # Must be set in .env
genai.configure(api_key=GOOGLE_API_KEY)

# Mock Database for Reports
# Structure: { id, building, floor, description, embedding (tensor or list), image_path }
REPAIR_REPORTS = [] 
NEXT_REPORT_ID = 1

# Lazy Load Models
_clip_model = None

def get_clip_model():
    global _clip_model
    if _clip_model is None:
        print("Loading CLIP Model...")
        # using a small model for demo speed: clip-ViT-B-32
        _clip_model = SentenceTransformer('sentence-transformers/clip-ViT-B-32')
        print("CLIP Model Loaded.")
    return _clip_model

# ==========================================
# ðŸ§  AI Analysis (Gemini)
# ==========================================

async def analyze_image_with_gemini(image_bytes: bytes) -> RepairAnalysisResult:
    """
    Gemini 3 Flash to analyze image.
    Enforces Korean output and strict JSON structure.
    """
    model = genai.GenerativeModel(
        model_name="gemini-1.5-flash", # Using 1.5 Flash as stable alias or 'gemini-1.5-pro' if needed. 3-flash-preview might need specific name check.
        # User requested 3-flash, usually accessed via preview names or 1.5 updates. 
        # I will use 'gemini-1.5-flash' as it's the current "Flash" standard avail in most keys, 
        # or 'models/gemini-1.5-flash-latest'. If fails, will fallback.
        generation_config={
            "response_mime_type": "application/json",
            "response_schema": RepairAnalysisResult
        }
    )
    
    # Image Prep
    # Gemini API supports bytes via Part if utilizing proper client.
    # Simpler via PIL -> Blob mapping in SDK? SDK supports PIL Image directly.
    pil_img = Image.open(BytesIO(image_bytes))
    
    prompt = """
    ë‹¹ì‹ ì€ ì‹œì„¤ ê´€ë¦¬ ë° ì•ˆì „ ì ê²€ ì „ë¬¸ê°€ AIìž…ë‹ˆë‹¤. 
    ì œê³µëœ ì‚¬ì§„ì„ ë¶„ì„í•˜ì—¬ ì‹œì„¤ë¬¼ì˜ ê³ ìž¥ ìƒíƒœë¥¼ ì§„ë‹¨í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
    
    **ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ìž‘ì„±í•˜ì„¸ìš”.**

    **ìš°ì„ ìˆœìœ„ íŒë‹¨ ê¸°ì¤€ (Priority Logic)**:
    1. **CRITICAL (ê¸´ê¸‰, ì ìˆ˜ 9-10)**: 
       - ê±°ì£¼ìžì˜ ê±´ê°•/ì•ˆì „ ìœ„í˜‘ (ì˜ˆ: í•˜ìˆ˜/ë³€ê¸° ì—­ë¥˜, ê°€ìŠ¤ ëˆ„ì¶œ, ì „ì„  ë…¸ì¶œ, í˜„ê´€ë¬¸/ë³´ì•ˆìž¥ì¹˜ íŒŒì†).
       - ì£¼ê±° ë¶ˆê°€ëŠ¥ ìƒíƒœ (ë‹¨ì „, ë‹¨ìˆ˜).
    2. **HIGH (ë†’ìŒ, ì ìˆ˜ 7-8)**: 
       - í•„ìˆ˜ ìƒí™œ ê¸°ëŠ¥ ë§ˆë¹„ (ì˜ˆ: ë‚œë°©/ì—ì–´ì»¨ ê³ ìž¥, ëƒ‰ìž¥ê³  ê³ ìž¥, ì‹±í¬ëŒ€ ëˆ„ìˆ˜).
    3. **MEDIUM (ì¤‘ê°„, ì ìˆ˜ 4-6)**: 
       - ê¸°ëŠ¥ìƒ ë¶ˆíŽ¸í•˜ë‚˜ ìƒí™œ ê°€ëŠ¥ (ì˜ˆ: ë°©ë¬¸ íŒŒì†, ì‹íƒ ì˜ìž íŒŒì†, ì „ë“± 1ê°œ ë‚˜ê°).
       - *ë¹„êµ*: í™”ìž¥ì‹¤ ë¬¸ì´ ìœ„ê¸‰í•˜ê²Œ ë¶€ì„œì¡Œë”ë¼ë„, ì˜¤ìˆ˜ê°€ ì—­ë¥˜í•˜ëŠ” ë³€ê¸°ë³´ë‹¤ëŠ” ìš°ì„ ìˆœìœ„ê°€ ë‚®ìŠµë‹ˆë‹¤.
    4. **LOW (ë‚®ìŒ, ì ìˆ˜ 1-3)**: 
       - ë¯¸ê´€ìƒ ë¬¸ì œ (ì˜ˆ: ë²½ì§€ ì°¢ì–´ì§, ìŠ¤í¬ëž˜ì¹˜).

    **ë¶„ì„ í•­ëª©**:
    - item: êµ¬ì²´ì ì¸ ë¬¼ê±´ ëª…ì¹­.
    - issue: ë¬¸ì œ í˜„ìƒ.
    - severity: CRITICAL, HIGH, MEDIUM, LOW ì¤‘ íƒ1.
    - priority_score: 1~10 ì‚¬ì´ ì •ìˆ˜.
    - reasoning: ì™œ ì´ ì‹¬ê°ë„ì¸ì§€ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª… (í•œêµ­ì–´).
    - repair_suggestion: ìˆ˜ë¦¬ ë°©ë²• ì œì•ˆ (í•œêµ­ì–´).
    - description: ìƒí™© ìš”ì•½ (í•œêµ­ì–´).
    """
    
    response = model.generate_content([prompt, pil_img])
    
    # Parse JSON
    try:
        data = json.loads(response.text)
        return RepairAnalysisResult(**data)
    except Exception as e:
        print(f"Gemini JSON Parse Error: {e}, Raw: {response.text}")
        # Fallback
        return RepairAnalysisResult(
            item="unknown", issue="unknown", 
            severity="MEDIUM", priority_score=5, reasoning="ë¶„ì„ ì‹¤íŒ¨", 
            repair_suggestion="", description="ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        )

# ==========================================
# ðŸ” Duplicate Detection (CLIP)
# ==========================================

async def check_duplicates(query_emb, building: str, floor: str, room_number: Optional[str] = None) -> List[DuplicateReportInfo]:
    # query_emb is already a tensor or numpy array
    
    duplicates = []
    
    # 2. Search in Mock DB
    for report in REPAIR_REPORTS:
        # Location Filter (Building & Floor match required)
        if report['building'] != building or report['floor'] != floor:
            continue
        
        # Room Filter
        report_room = report.get('room_number')
        if room_number != report_room:
            continue
            
        # Similarity
        if report.get('embedding') is not None:
            # query_emb -> torch tensor if needed, or use util.pytorch_cos_sim logic
            # Assuming query_emb is loaded via np.load, it's a numpy array.
            # util.pytorch_cos_sim handles numpy arrays fine.
            sim = util.pytorch_cos_sim(query_emb, report['embedding'])[0][0].item()
            
            # Threshold: 0.80 (Adjusted for test cases)
            if sim >= 0.80:
                loc_str = f"{report['building']} {report['floor']}F"
                if report_room:
                    loc_str += f" {report_room}í˜¸"
                    
                duplicates.append(DuplicateReportInfo(
                    reportId=report['id'],
                    similarity=round(sim, 2),
                    description=report['description'],
                    location=loc_str
                ))
    
    # Sort by sim desc
    duplicates.sort(key=lambda x: x.similarity, reverse=True)
    return duplicates

async def save_report(analysis: RepairAnalysisResult, query_emb, building: str, floor: str, room_number: Optional[str] = None):
    """
    In-memory save for future duplicate checks. 
    In real app, save image to S3/Disk and Embedding to VectorDB.
    """
    global NEXT_REPORT_ID
    
    REPAIR_REPORTS.append({
        "id": NEXT_REPORT_ID,
        "building": building,
        "floor": floor,
        "room_number": room_number,
        "description": analysis.description,
        "embedding": query_emb
    })
    NEXT_REPORT_ID += 1

# ==========================================
# ðŸš€ Main Logic
# ==========================================

from .models import RepairRequest

async def process_repair_request(req: RepairRequest) -> RepairResponse:
    # 1. Read Image from Path (for Gemini)
    try:
        with open(req.imagePath, "rb") as f:
            content = f.read()
    except Exception as e:
        raise ValueError(f"Image not found at {req.imagePath}")

    # 2. Load Vector from Path (for Duplicate Check)
    try:
        # Load .npy file
        # Assuming it is a 1D or 2D array. CLIP returns [1, 512].
        query_emb = np.load(req.vectorPath)
        # Ensure it's compatible with sentence-transformers util
    except Exception as e:
        raise ValueError(f"Vector file not found at {req.vectorPath}")
    
    # Parallelize? Gemini & CLIP Logic
    
    # 3. Analyze (Gemini)
    analysis_task = analyze_image_with_gemini(content)
    
    # 4. Check Duplicates (Use loaded vector)
    duplicates_task = check_duplicates(query_emb, req.building, req.floor, req.room_number)
    
    analysis, duplicates = await asyncio.gather(analysis_task, duplicates_task)
    
    # 5. Save current report
    await save_report(analysis, query_emb, req.building, req.floor, req.room_number)
    
    return RepairResponse(
        analysis=analysis,
        duplicates=duplicates,
        is_new=(len(duplicates) == 0)
    )
